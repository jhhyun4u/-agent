"""
Claude ëª¨ë¸ ì „ëµ ë° í† í°/ë¹„ìš© ìµœì í™”.

v3.0: ë‹¤ë‹¨ê³„ ëª¨ë¸ í‹°ì–´ë§ + í•œêµ­ì–´ í† í° ìµœì í™”

ì„¤ê³„: Part VII - Claude ëª¨ë¸ ì „ëµ ë° í† í°/ë¹„ìš© ìµœì í™”
"""

from enum import Enum
from typing import Literal
from langchain_anthropic import ChatAnthropic


class ModelTier(str, Enum):
    """Claude ëª¨ë¸ í‹°ì–´"""
    OPUS = "claude-opus-4-5-20250929"      # ìµœê³  ì„±ëŠ¥, ê°€ì¥ ë¹„ìŒˆ
    SONNET = "claude-sonnet-4-5-20250929"  # ìµœì  ê· í˜•
    HAIKU = "claude-haiku-4-5-20251001"    # ì´ˆê³ ì†, ì €ë¹„ìš©


class ModelConfig:
    """ëª¨ë¸ë³„ ê°€ê²© ë° íŠ¹ì„±"""

    PRICES = {
        ModelTier.OPUS: {
            "input": 5.00,              # $/MTok
            "output": 25.00,
            "cache_write": 6.25,
            "cache_read": 0.50,
        },
        ModelTier.SONNET: {
            "input": 3.00,
            "output": 15.00,
            "cache_write": 3.75,
            "cache_read": 0.30,
        },
        ModelTier.HAIKU: {
            "input": 0.80,
            "output": 4.00,
            "cache_write": 1.00,
            "cache_read": 0.08,
        },
    }

    CONTEXT_WINDOWS = {
        ModelTier.OPUS: 200_000,
        ModelTier.SONNET: 200_000,
        ModelTier.HAIKU: 200_000,
    }

    @staticmethod
    def get_safe_limit(model: ModelTier) -> int:
        """ëª¨ë¸ì˜ ì•ˆì „ í† í° í•œë„ (ì¶œë ¥ ì—¬ìœ  80% ì‚¬ìš©)"""
        limit = ModelConfig.CONTEXT_WINDOWS.get(model, 200_000)
        return int(limit * 0.80)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë…¸ë“œë³„ ëª¨ë¸ ë°°ì • ì „ëµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

NODE_MODEL_TIER = {
    # Supervisor (íŒë‹¨ ì •í™•ì„± ì¤‘ìš”)
    "supervisor_plan": ModelTier.SONNET,
    "supervisor_route": None,  # LLM ë¯¸ì‚¬ìš© (ê·œì¹™ ê¸°ë°˜)

    # RFP ë¶„ì„ ì—ì´ì „íŠ¸
    "extract_document": None,
    "clean_text": None,
    "structural_analysis": ModelTier.SONNET,
    "implicit_analysis": ModelTier.SONNET,
    "client_language": ModelTier.HAIKU,
    "qualification_check": ModelTier.HAIKU,

    # ì „ëµ ìˆ˜ë¦½ ì—ì´ì „íŠ¸
    "analyze_competition": ModelTier.SONNET,
    "allocate_resources": ModelTier.HAIKU,
    "develop_strategy": ModelTier.SONNET,
    "assign_personnel": ModelTier.HAIKU,

    # ì„¹ì…˜ ìƒì„± ì—ì´ì „íŠ¸ (ê¸°ë³¸ê°’, ì„¹ì…˜ë³„ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
    "plan_phases": ModelTier.HAIKU,
    "generate_section": ModelTier.SONNET,

    # í’ˆì§ˆ ê´€ë¦¬ ì—ì´ì „íŠ¸
    "critique_sections": ModelTier.SONNET,
    "check_consistency": ModelTier.HAIKU,
    "revise_sections": ModelTier.HAIKU,

    # ë¬¸ì„œ ì¶œë ¥ ì—ì´ì „íŠ¸
    "gen_exec_summary": ModelTier.SONNET,
    "final_edit": ModelTier.SONNET,
    "apply_template": None,
    "export_document": None,
}


# ì„¹ì…˜ë³„ ëª¨ë¸ ì˜¤ë²„ë¼ì´ë“œ
SECTION_MODEL_TIER = {
    # Sonnet: ì „ëµì  ì‚¬ê³ , ì°½ì˜ì  ì‘ë¬¸ í•„ìš”
    "sec_01_understanding": ModelTier.SONNET,
    "sec_02_strategy": ModelTier.SONNET,
    "sec_03_methodology": ModelTier.SONNET,
    "sec_06_budget": ModelTier.SONNET,
    "sec_07_outcomes": ModelTier.SONNET,

    # Haiku: ì •í˜• êµ¬ì¡°, ë°ì´í„° ë‚˜ì—´ ì¤‘ì‹¬ (Few-shotìœ¼ë¡œ í’ˆì§ˆ ë³´ì™„)
    "sec_04_organization": ModelTier.HAIKU,
    "sec_05_schedule": ModelTier.HAIKU,
    "sec_08_risk": ModelTier.HAIKU,
    "sec_09_references": ModelTier.HAIKU,
}


def get_node_model(node_name: str) -> ModelTier | None:
    """ë…¸ë“œëª…ìœ¼ë¡œ ì‚¬ìš©í•  ëª¨ë¸ ë°˜í™˜"""
    return NODE_MODEL_TIER.get(node_name)


def get_section_model(section_id: str) -> ModelTier:
    """ì„¹ì…˜ IDë¡œ ì‚¬ìš©í•  ëª¨ë¸ ë°˜í™˜ (ê¸°ë³¸ê°’: Sonnet)"""
    return SECTION_MODEL_TIER.get(section_id, ModelTier.SONNET)


def create_llm(model_tier: ModelTier, temperature: float = 0, **kwargs) -> ChatAnthropic:
    """ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤"""
    return ChatAnthropic(model=model_tier.value, temperature=temperature, **kwargs)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í•œêµ­ì–´ í† í° ê´€ë¦¬ (Claude íŠ¹í™”)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TokenBudget:
    """Claude ëª¨ë¸ìš© í† í° ì˜ˆì‚° ê´€ë¦¬"""

    # Claude í† í¬ë‚˜ì´ì €ì˜ í•œêµ­ì–´ ì²˜ë¦¬ íŠ¹ì„±:
    # - í•œê¸€ 1ê¸€ì â‰ˆ 1.2í† í° (í‰ê· )
    # - ì˜ë¬¸/ìˆ«ì â‰ˆ 0.25í† í°/ê¸€ì
    # - ê³µë°±/ê¸°í˜¸ â‰ˆ 0.5í† í°

    @staticmethod
    def estimate_tokens_korean(text: str) -> int:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ì˜ Claude í† í° ìˆ˜ ì¶”ì •"""
        korean_chars = sum(1 for c in text if '\uac00' <= c <= '\ud7a3')
        ascii_chars = sum(1 for c in text if c.isascii() and c.isalnum())
        other_chars = len(text) - korean_chars - ascii_chars

        return int(korean_chars * 1.2 + ascii_chars * 0.25 + other_chars * 0.5)

    @staticmethod
    def truncate_for_context(text: str, max_tokens: int) -> str:
        """ìµœëŒ€ í† í° ìˆ˜ì— ë§ê²Œ í…ìŠ¤íŠ¸ ìë¥´ê¸°"""
        # Claude í•œêµ­ì–´ ì—­ë³€í™˜: 1í† í° â‰ˆ 0.83ê¸€ì
        max_chars = int(max_tokens * 0.83)
        if len(text) <= max_chars:
            return text
        return text[:max_chars] + "\n\n... (ë¶„ëŸ‰ ì´ˆê³¼ë¡œ ì´í•˜ ìƒëµ)"

    @staticmethod
    def budget_for_node(node_name: str) -> dict:
        """ë…¸ë“œë³„ í† í° ì˜ˆì‚° ê°€ì´ë“œ"""
        BUDGETS = {
            "structural_analysis": {"input": 50_000, "output": 8_000},
            "implicit_analysis": {"input": 30_000, "output": 5_000},
            "develop_strategy": {"input": 40_000, "output": 10_000},
            "generate_section": {"input": 60_000, "output": 15_000},
            "critique_sections": {"input": 80_000, "output": 10_000},
            "gen_exec_summary": {"input": 50_000, "output": 8_000},
        }
        return BUDGETS.get(node_name, {"input": 40_000, "output": 8_000})

    @staticmethod
    def max_tokens_for_section(target_pages: float) -> int:
        """ì„¹ì…˜ ëª©í‘œ ë¶„ëŸ‰ì— ë§ëŠ” max_tokens ë™ì  ê³„ì‚°.
        
        í•œêµ­ì–´ ~2,160í† í°/í˜ì´ì§€ Ã— 1.2 ë§ˆì§„.
        ê³ ì • max_tokensëŠ” ì§§ì€ ì„¹ì…˜ì—ì„œ ì¥í™©í•œ ì¶œë ¥ì„,
        ê¸´ ì„¹ì…˜ì—ì„œ ì˜ë¦¼ì„ ìœ ë°œí•˜ë¯€ë¡œ, ë™ì ìœ¼ë¡œ ì„¤ì •.
        """
        TOKENS_PER_PAGE_KO = 2_160
        return int(target_pages * TOKENS_PER_PAGE_KO * 1.2)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Effort íŒŒë¼ë¯¸í„° ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EFFORT_CONFIG = {
    # ê°„ë‹¨í•œ ì‘ì—… (low)
    "client_language": "low",
    "qualification_check": "low",
    "allocate_resources": "low",
    "check_consistency": "low",
    "plan_phases": "low",
    "assign_personnel": "low",

    # ë³µì¡í•œ ì‘ì—… (high)
    "develop_strategy": "high",
    "critique_sections": "high",
    "gen_exec_summary": "high",

    # ê¸°ë³¸ê°’ (medium)
}


def get_effort(node_name: str) -> Literal["low", "medium", "high"]:
    """ë…¸ë“œì˜ Effort íŒŒë¼ë¯¸í„°"""
    return EFFORT_CONFIG.get(node_name, "medium")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Extended Thinking ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

THINKING_CONFIG = {
    # (enable, budget_tokens)
    "implicit_analysis": (True, 4_000),   # ìˆ¨ì€ ì˜ë„ 5~7ê°œ ì¶”ë¡ ì— ì¶©ë¶„
    "develop_strategy": (True, 8_000),    # SWOT ê¸°ë°˜ ì „ëµ ë„ì¶œì— ì¶©ë¶„
    "critique_sections": (True, 5_000),   # 6ëŒ€ ì¶• í‰ê°€ì— ì¶©ë¶„
    "gen_exec_summary": (False, 0),       # ì •ë³´ ì·¨í•© ì¤‘ì‹¬ â†’ ë¶ˆí•„ìš”
}


def should_use_thinking(node_name: str) -> bool:
    """ë…¸ë“œì—ì„œ Extended Thinking ì‚¬ìš© ì—¬ë¶€"""
    config = THINKING_CONFIG.get(node_name, (False, 0))
    return config[0]


def get_thinking_budget(node_name: str) -> int:
    """ë…¸ë“œì˜ Extended Thinking ì˜ˆì‚°"""
    config = THINKING_CONFIG.get(node_name, (False, 0))
    return config[1]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TokenUsageTracker:
    """ë…¸ë“œë³„ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ë¹„ìš© ê³„ì‚°"""

    def __init__(self):
        self.records = []

    def record(
        self,
        node_name: str,
        model_tier: ModelTier,
        input_tokens: int,
        output_tokens: int,
        cache_creation_tokens: int = 0,
        cache_read_tokens: int = 0,
    ):
        """í† í° ì‚¬ìš© ê¸°ë¡"""
        cost = self._calculate_cost(
            model_tier, input_tokens, output_tokens,
            cache_creation_tokens, cache_read_tokens
        )

        self.records.append({
            "node": node_name,
            "model": model_tier.value,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "cache_creation": cache_creation_tokens,
            "cache_read": cache_read_tokens,
            "cost_usd": cost,
        })

    def _calculate_cost(
        self,
        model_tier: ModelTier,
        input_tokens: int,
        output_tokens: int,
        cache_creation: int = 0,
        cache_read: int = 0,
    ) -> float:
        """ì‚¬ìš© ë¹„ìš© ê³„ì‚°"""
        prices = ModelConfig.PRICES[model_tier]

        # ì…ë ¥ ë¹„ìš© = (ì „ì²´ ì…ë ¥ í† í° - ìºì‹œ ê´€ë ¨) Ã— ê¸°ë³¸ê°€ + ìºì‹œ ìƒì„± Ã— ë†’ì€ê°€ + ìºì‹œ ì½ê¸° Ã— ë‚®ì€ê°€
        input_cost = (
            (input_tokens - cache_creation - cache_read) * prices["input"]
            + cache_creation * prices["cache_write"]
            + cache_read * prices["cache_read"]
        ) / 1_000_000

        output_cost = (output_tokens * prices["output"]) / 1_000_000

        return input_cost + output_cost

    def report(self) -> dict:
        """ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ë³´ê³ ì„œ"""
        if not self.records:
            return {
                "total_tokens": 0,
                "total_cost": 0.0,
                "records": [],
            }

        total_input = sum(r["input_tokens"] for r in self.records)
        total_output = sum(r["output_tokens"] for r in self.records)
        total_cost = sum(r["cost_usd"] for r in self.records)

        by_node = {}
        for r in self.records:
            if r["node"] not in by_node:
                by_node[r["node"]] = 0.0
            by_node[r["node"]] += r["cost_usd"]

        top5_costly = sorted(by_node.items(), key=lambda x: -x[1])[:5]

        return {
            "total_input_tokens": total_input,
            "total_output_tokens": total_output,
            "total_tokens": total_input + total_output,
            "total_cost_usd": round(total_cost, 4),
            "average_cost_per_call": round(total_cost / max(len(self.records), 1), 4),
            "llm_calls": len(self.records),
            "top5_costly_nodes": top5_costly,
        }

    def recommend_optimizations(self) -> list[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­"""
        report = self.report()
        recs = []

        total_cost = report["total_cost_usd"]

        for node, cost in report["top5_costly_nodes"]:
            if cost > total_cost * 0.3:
                pct = (cost / total_cost) * 100
                recs.append(
                    f"ğŸ“Š {node}: ${cost:.2f} ({pct:.0f}%) - "
                    f"ëª¨ë¸ ë‹¤ìš´ê·¸ë ˆì´ë“œ ë˜ëŠ” ì…ë ¥ ì¶•ì†Œ ê²€í† "
                )

        return recs
